# -*- coding: utf-8 -*-
"""Major_project1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DD9_FaWZPCq44xXe9MeprAl4GyY6qwxm
"""

#from google.colab import files
#uploaded = files.upload()

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
# %matplotlib inline
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

def find_target_func(scores):
    if scores[0] > scores[1]:
        return 1
    elif scores[0] < scores[1]:
        return -1
    else:
        return 0

"""Create a target feature where 1 denotes Home team wins, 0 denotes a draw, and -1 denotes away team victory."""

df = pd.read_csv("../data/data.csv")

df['target'] = df[['Score_home', 'Score_away']].apply(find_target_func, axis=1)
df.sort_values('MatchID', inplace=True)
df



df.columns

#Removing non important features
columns_to_drop = ['MatchID', 'Home_team', 'Away_team', 'Score_home', 'Score_away', 'year']
df_mod = df.drop(columns = columns_to_drop)

"""We will now analyze correlation between different features."""

import seaborn as sns
away_features = [f for f in list(df) if '_away' in f]
corr = df[away_features].corr()
plt.figure(figsize = (8,8))
sns.heatmap(corr, square=True, cmap="YlGnBu",linewidths=0.1)
plt.show()

"""Examples of few features that looks strongly correlated are:
1) Possession home and touches/passes home,
2) Shots home and Shots on target home,
3) Score home and Shots on target.
These are intuitive as more possession leads to more touches.
"""

import matplotlib.pyplot as plt
home_features = [f for f in list(df_mod) if '_home' in f]
n_figs = len(home_features)
columns = 4

fig, axes = plt.subplots(int(n_figs/columns), columns, figsize = (15,15))
plt.subplots_adjust(hspace=.5)


for i,feature in enumerate(home_features):
    row = int(i/columns)
    column = i%columns
    axes[row, column].hist(df[feature].values, 20)
    axes[row, column].set_title(feature)

n_figs = len(away_features)
columns = 4

fig, axes = plt.subplots(int(n_figs/columns), columns, figsize = (15,15))
plt.subplots_adjust(hspace=.5)

away_features = [f for f in list(df_mod) if '_away' in f]
for i,feature in enumerate(away_features):
    row = int(i/columns)
    column = i%columns
    axes[row, column].hist(df[feature].values, 20)
    axes[row, column].set_title(feature)

#lets see target distribution
plt.figure(figsize=(8,7))
sns.distplot(df.target)
plt.show()

"""Seems like home team wins more than away which is shown by more 1s."""

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
import numpy as np

df_mod = df_mod.drop(columns = ['target'])
X = df_mod.values
y = df['target'].values
features = df_mod.columns
forest = RandomForestClassifier(n_estimators=500, random_state=43)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=43)

forest.fit(X_train, y_train)

importances = forest.feature_importances_
indices = np.argsort(importances)[::-1]

for f in range(X_train.shape[1]):
    print("%2d) %-*s %f" % (f + 1, 30,features[indices[f]], importances[indices[f]]))

"""Red card have significant effect on game but here is least significant because of rare occurence."""

def goal_diff(scores):
    gd_dict = {}
    for game in scores:
        id, home_team, away_team, home_goals, away_goals = game
        score = home_goals - away_goals# in perspective of home team
        gd_dict[home_team] = gd_dict.get(home_team, []) + [(id,score)]
        gd_dict[away_team] = gd_dict.get(away_team, []) + [(id, -1*score)]
    return gd_dict

def get_window(matchID, team, gd_vectors, window=5, boolean=False):
    team_results = gd_vectors[team]
    idx = -1
    for i, result in enumerate(team_results):
        if result[0] == matchID:
            id = i
            break
    if idx < window-1:
        return None
    return [team_results[i][1] for i in range(idx-window, idx)]

import math
def form_values_exp(matchID, team, gd, alpha, boolean=True):
    avg_vec, i = [], 1
    while sum(avg_vec) < 1:
        avg_vec.append(math.e ** (-1*(alpha*i)))
        i += 1
    avg_vec = sorted(avg_vec)
    previous_results = get_window(matchID, team, gd, len(avg_vec), boolean)
    if not previous_results:
        return 0
    return np.dot(np.array(avg_vec), np.array(previous_results))

"""Include a special feauture called form (streak) from past 5 games."""

scores = df[['MatchID', 'Home_team', 'Away_team', 'Score_home', 'Score_away']].values
gd = goal_diff(scores)

home_form, away_form = [], []
for game in scores:
    id, home_team, away_team, home_score, away_score = game
    home_form.append(form_values_exp(id, home_team, gd, alpha=.5))
    away_form.append(form_values_exp(id, away_team, gd, alpha=.5))
    
df['form_home'] = pd.Series(home_form)
df['form_away'] = pd.Series(away_form)

from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import GradientBoostingClassifier
from sklearn import svm
from sklearn.neural_network import MLPClassifier

lr = LogisticRegression(random_state=0, solver='lbfgs', max_iter=10000, multi_class='multinomial')
rf = RandomForestClassifier(n_estimators=1000, max_depth=10, random_state=0)
gb = GradientBoostingClassifier()
SVM = svm.SVC(decision_function_shape='ovo')
# NN = MLPClassifier(solver='lbfgs', alpha=1e-4, max_iter=1000, hidden_layer_sizes=(150,10), random_state=1)
NN = MLPClassifier(solver='lbfgs', alpha=1e-4, max_iter=1000, hidden_layer_sizes=(80,4), random_state=1)

clf_labels = ['Logistic Regression', 'Random Forest', 'Gradient Boosting', 'Support Vector Machines', 'Neural Network']
all_clf = [lr, rf, gb, SVM, NN]

#PCA
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA

sc = StandardScaler()
X_train_std = sc.fit_transform(X_train)
X_test_std = sc.transform(X_test)

pca = PCA()
X_train_pca = pca.fit_transform(X_train_std)
X_test_pca = pca.fit_transform(X_test_std)

plt.bar(range(1,33), pca.explained_variance_ratio_, alpha=0.5, align='center')
plt.step(range(1,33), np.cumsum(pca.explained_variance_ratio_), where='mid')
plt.ylabel('Explained Variance Ratio')
plt.xlabel('Principal Components')
plt.show()

"""With around 10 components we see 60% explained variance, with around 15 components around 80% of explained variance and somewhere with 25 components around 90% of explained variance."""

pca_15 = PCA(n_components = 15)
X_train_pca_15 = pca_15.fit_transform(X_train_std)
X_test_pca_15 = pca_15.transform(X_test_std)

pca_20 = PCA(n_components=20)
X_train_pca_20 = pca_20.fit_transform(X_train_std)
X_test_pca_20 = pca_20.transform(X_test_std)

pca_25 = PCA(n_components = 25)
X_train_pca_25 = pca_25.fit_transform(X_train_std)
X_test_pca_25 = pca_25.transform(X_test_std)


for label,clf in zip(clf_labels, all_clf):
    print('Model:', label)
    model_orig = clf.fit(X_train, y_train)
    print("Score in original dimension: ", model_orig.score(X_test, y_test))
    model_pca_15 = clf.fit(X_train_pca_15, y_train)
    print("Score in reduced dimension with 15 components: ", model_pca_15.score(X_test_pca_15, y_test))
    model_pca_20 = clf.fit(X_train_pca_20, y_train)
    print("Score in reduced dimension with 20 components: ", model_pca_20.score(X_test_pca_20, y_test))
    model_pca_25 = clf.fit(X_train_pca_25, y_train)
    print("Score in reduced dimension with 25 components: ", model_pca_25.score(X_test_pca_25, y_test), "\n")

"""Reducing dimension by PCA does not do much good to our model. We get best performance while using Gradient Boosting with full dimensions or Linear Regression with 15 dimensions. We can keep 15 components."""

# NN = MLPClassifier(solver='lbfgs', alpha=1e-3, max_iter=10000, hidden_layer_sizes=(1000,10), random_state=1)
# model_temp = NN.fit(X_train, y_train)
# print("Score in original dimension: ", model_temp.score(X_test, y_test))
# NN = MLPClassifier(solver='lbfgs', alpha=1e-3, max_iter=10000, hidden_layer_sizes=(200,2), random_state=1)
# model_temp = NN.fit(X_train, y_train)
# print("Score in original dimension: ", model_temp.score(X_test, y_test))
# NN = MLPClassifier(solver='lbfgs', alpha=1e-3, max_iter=10000, hidden_layer_sizes=(300,3), random_state=1)
# model_temp = NN.fit(X_train, y_train)
# print("Score in original dimension: ", model_temp.score(X_test, y_test))
# NN = MLPClassifier(solver='lbfgs', alpha=1e-3, max_iter=10000, hidden_layer_sizes=(400,4), random_state=1)
# model_temp = NN.fit(X_train, y_train)
# print("Score in original dimension: ", model_temp.score(X_test, y_test))
# NN = MLPClassifier(solver='lbfgs', alpha=1e-3, max_iter=10000, hidden_layer_sizes=(500,5), random_state=1)
# model_temp = NN.fit(X_train, y_train)
# print("Score in original dimension: ", model_temp.score(X_test, y_test))

"""Using ensemble model"""

from sklearn.model_selection import cross_val_score
from sklearn.ensemble import VotingClassifier

estimator_list = [('lr',lr), ('rf',rf), ('gb', gb), ('SVM',SVM),('NN',NN)]
enclf = VotingClassifier(estimators=estimator_list, voting='hard')
scores = cross_val_score(estimator=enclf, X=X_train, y=y_train, cv=10, scoring='accuracy')
scores

print("Accuracy: %0.2f (+/- %0.2f)" %(scores.mean(), scores.std()))

"""**Expected Goals**
To predict number of goals scored by each team within a single game.
"""

fig, (ax1,ax2) = plt.subplots(2,1, figsize=(8,7))
ax1.hist(df.Score_home, 20)
ax1.set_title("Home Score")
ax2.hist(df.Score_away, 20)
ax2.set_title("Away Score")

"""This distribution looks like exponential which is intuitive as it is hard to score more goals and it depends more on in-game stats of team.

Now we will reduce features which we obtained after feature reduction techniques and correlation we looked at earlier.
"""

Target_proxies = ['MatchID', 'Team', 'year', 'Score']
#based on correlation and feature importance
Features_to_drop = ['Shots_home', 'Shots_away', 'Touches_home', 'Possession_home', 'Possession_away',
'Touches_away','Tackles_home', 'Tackles_away', 'Arrivals_home', 'Arrivals_away',
'Departures_home', 'Departures_away', 'Corners_home', 'Corners_away',
'Red_cards_home', 'Red_cards_away', 'Yellow_cards_home', 'Yellow_cards_away', 'form_home', 'form_away']

"""As form of Goal difference is mostly a 0 value because of exponential decrease in importance, it does not have a drastic importance. So drop it as well."""

df_mod_2 = df.drop(columns=Features_to_drop)
df_mod_2

"""df_final becomes our X. Find y using the target varible."""

X1 = df_mod_2.drop(columns=['MatchID', 'Home_team', 'Away_team', 'year'])
y1 = df['target'].values

X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size=.2, random_state=43)

sc = StandardScaler()
X1_train_std = sc.fit_transform(X_train)
X1_test_std = sc.transform(X_test)

lr = LogisticRegression(random_state=0, solver='lbfgs', max_iter=10000, multi_class='multinomial')

lr.fit(X1_train_std, y1_train)
print("Accuracy: ", lr.score(X1_test_std, y1_test))

"""Thus using Linear regression and reducing features as analyzed by techniques before, we get an accuracy of 62.82% of predicting the result of the game of leagues."""

home_attributes = ['MatchID', 'Home_team', 'year'] + [i for i in list(df_mod_2) if 'home' in i]
away_attributes = ['MatchID', 'Away_team', 'year'] + [i for i in list(df_mod_2) if 'away' in i]

"""Have a dataframe with only one team's features"""

final = []
for _, row in df_mod_2.iterrows():
    home_team = [row[i] for i in home_attributes] + [0]
    away_team = [row[i] for i in away_attributes] + [1]
    final.append(home_team)
    final.append(away_team)

print(final[-1])

features = ['MatchID', 'Team', 'year'] + [i.split('_')[0] for i in list(df_mod_2) if 'home' in i] + ['IsHome']
print(features)

df_final = pd.DataFrame(final, columns = features)
df_final

"""Now find ExpectedGoals. Using Expected Goals, we will find a team's expected number of goals scored based on some distribution and previos results. Just by comparing these xG, we will declare the winner for a game."""

from sklearn.svm import SVR
from sklearn.neural_network import MLPRegressor
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import Lasso, LassoLars, Ridge, BayesianRidge, SGDRegressor, LinearRegression
from sklearn.ensemble import AdaBoostRegressor, ExtraTreesRegressor, GradientBoostingRegressor, RandomForestRegressor

all_regs = [SVR(), MLPRegressor(), KNeighborsClassifier(), Lasso(), LassoLars(),
            Ridge(), BayesianRidge(), SGDRegressor(), AdaBoostRegressor(),
            ExtraTreesRegressor(), GradientBoostingRegressor(), 
            RandomForestRegressor(), LinearRegression()]

from sklearn.metrics import mean_squared_error

df_final_mod = df_final.drop(columns = Target_proxies)

X = df_final_mod.values
y = df_final['Score'].values

reg_dict = {str(type(reg)).split('.')[-1][:-2]: [] for reg in all_regs}
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=43)

for reg in all_regs:
    reg_name = str(type(reg)).split('.')[-1][:-2]
    reg.fit(X_train, y_train)
    y_pred = reg.predict(X_test)
    reg_dict[reg_name].append( ("rmse", mean_squared_error(y_test, y_pred)**.5))

rmse = []
for k,v in reg_dict.items():
    rmse.append((k, v[0][1]))
sorted(rmse, key=lambda x: x[1])

"""Again Gradient Boosting Regressor seems to be giving best results."""

from sklearn.model_selection import RandomizedSearchCV

gb_params = {'loss': ['ls', 'lad', 'huber'],
             'subsample': [0.2, 0.5, 1.0],
             'min_samples_split': [2, 5, 10],
             'max_depth': [3, 5, 7, 10]
             }

gb_cv = RandomizedSearchCV(GradientBoostingRegressor(), gb_params, cv=5,
                           n_jobs=-1, n_iter=20)
_ = gb_cv.fit(X,y)

cv_res_dict = gb_cv.cv_results_
for param_set, test_score in zip(cv_res_dict['params'], cv_res_dict['mean_test_score']):
    print(param_set, " : ", test_score )

"""So we will use Gradient Boosting model with ls loss function which gives result:

{'subsample': 0.2, 'min_samples_split': 2, 'max_depth': 10, 'loss': 'ls'}  :  0.14525918395391843

#Prediction
"""

window = 10
gbr = GradientBoostingRegressor(loss='ls', max_depth=10, min_samples_split=2, 
                                subsample=0.2)
year_to_test = 2018

#Train
features_to_drop = ['MatchID', 'Team', 'year', 'Score']
X = df_final[df_final.year != year_to_test].drop(columns=features_to_drop).values
y = df_final[df_final.year != year_to_test].Score.values
goal_model = gbr.fit(X,y)

"""Predict Shots, Passes, Clearances, Offsides and Fouls using model trained on rest years"""

model_map = {'Shots': GradientBoostingRegressor(),
             'Passes': LinearRegression(),
             'Clearances': GradientBoostingRegressor(),
             'Fouls': Ridge(),
             'Offsides': GradientBoostingRegressor()
             }

features_to_drop = ['MatchID', 'Team', 'year']

for feature,clf in model_map.items():
    teams = df_final[df_final.year != year_to_test].Team.unique()
    X_list, y_list = [], []
    for team in teams:
        team_df = df_final[df_final.Team == team]
        fit_df = team_df[team_df.year != year_to_test].drop(columns=features_to_drop + [feature])
        for i in range(team_df.shape[0] - window - 1):
            X_vec = fit_df.iloc[i:i+window].values.flatten()
            if X_vec.shape[0] == 8 * window:
                X_list.append(X_vec)
                y_list.append(team_df[feature].values[i+window+1])
        
    X = np.vstack(X_list)
    y = np.array(y_list)
    clf.fit(X,y)
    model_map[feature] = clf

simulated_df = df_final[df_final.year == 2017]
simulated_df.head()

sim_stddev_map = {feature: np.std(df_final[feature]) for feature in model_map.keys()}
sim_mean_map = {feature: np.mean(df_final[feature]) for feature in model_map.keys()}

print(sim_mean_map)
print(sim_stddev_map)

test_season = df_final[df_final.year == year_to_test].drop(columns = list(model_map.keys()) + ['Score'])
test_season.head()

def fit_game(game, df, model_map, goal_model, noise_map, window=10,
             relegated=['Hull', 'Middlesbrough', 'Sunderland'],
             features_to_drop = ['MatchID', 'Team', 'year']):
    team_df = df[df.Team == game.Team]
    if team_df.shape[0] < window:#Newly promoted teams take same form as last season relegated teams
        relegated_df = df[(df.Team == relegated[0]) |
                          (df.Team == relegated[1]) | 
                          (df.Team == relegated[2]) ]
        team_df = pd.concat([relegated_df, team_df])
    
    #Insert randomly distribution in statistical features
    new_row = {'MatchID':game.MatchID, 'Team':game.Team, 'year':game.year,
               'Score':None, 'Shots':None, 'Passes':None, 'Offsides':None,
               'Fouls':None, 'Expenditures':game.Expenditures, 'Income': game.Income,
               'IsHome':game.IsHome}
    
    for feature in model_map.keys():
        X = team_df.tail(window).drop(columns=features_to_drop + [feature]).values.flatten().reshape(1,-1)
        noise = noise_map[feature]*np.random.normal()
        new_row[feature] = max(int(model_map[feature].predict(X)[0]) + noise, 0)
    
    goal_features = ['Shots', 'Passes', 'Clearances', 'Offsides', 'Fouls', 'Expenditures', 'Income', 'IsHome']
    X_score_list = [new_row[feature] for feature in goal_features]
    X_score = np.array(X_score_list).reshape(1,-1)
    new_row['Score'] = int(goal_model.predict(X_score)[0])
    return new_row

for row in test_season.iterrows():
    game = row[1]
    sim_res = fit_game(game, simulated_df, model_map, goal_model, sim_stddev_map)
    simulated_df = simulated_df.append(sim_res, ignore_index=True)

print(simulated_df.head(10))

def get_team_points(df, test_year = 2018):
    year_df = df[df.year == test_year]
    point_dict = { team: [] for team in year_df.Team.unique() }
    match_ids = year_df.MatchID.unique() # need to match games on MatchID
    for match_id in match_ids:
        game = year_df[year_df.MatchID == match_id]
        result = game[['Team', 'Score']].values
        if result[0][1] == result[1][1]:  # draw
            point_dict[result[0][0]].append(1)
            point_dict[result[1][0]].append(1)
        elif result[0][1] > result[1][1]:
            point_dict[result[0][0]].append(3)
            point_dict[result[1][0]].append(0)
        else:
            point_dict[result[0][0]].append(0)
            point_dict[result[1][0]].append(3)

    table = []
    for team, point_list in point_dict.items():
        table.append( (team, sum(point_list)) )
    return table

points = get_team_points(simulated_df)
sorted(points, key=lambda x: -x[1])

"""This model rightly predicts that West Brom will finish bottom of the table and will be relegated and that Manchester United will come close to winning the premier league. However it wrongly predicts that Man City will be struggling and that Southhampton will finish in top 4.

Now we will do more runs to get a better model.
"""

runs = 50

season_df = df_final[df_final.year == year_to_test].drop(columns = list(model_map.keys()) + ['Score'])
base_df = df_final[df_final.year == (year_to_test-1)]

total_points = {team: [] for team in season_df.Team.unique()}
positions = {team: [] for team in season_df.Team.unique()}

for run in range(runs):
    run_df = base_df.copy()
    for row in season_df.iterrows():
        game = row[1]
        simulated_res = fit_game(game, run_df, model_map, goal_model, sim_stddev_map)
        run_df = run_df.append(simulated_res, ignore_index=True)

    simulated_table = get_team_points(run_df)
    for points in simulated_table:
        total_points[points[0]].append(points[1])

    sorted(simulated_table, key=lambda x: -x[1])
    standings = [t[0] for t in simulated_table]

    for i,team in enumerate(standings):
        positions[team].append(i+1)

sorted( [(team, sum(points)/len(points)) for team, points in total_points.items()], key = lambda x: -x[1] )

"""This prediction looks very much similar to actual 2018 Premier League Table. All top 6 predicted teams are correct and 3 out of 4 teams are correctly predicted to be in top 4."""

